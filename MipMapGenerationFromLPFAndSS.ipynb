{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import pytorch_msssim\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from skimage.measure import block_reduce\n",
    "import math\n",
    "import copy\n",
    "from PIL import Image, ImageFilter\n",
    "import skimage.measure\n",
    "from scipy import ndimage\n",
    "import scipy.signal as signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "################ Filters #################\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Filter\n",
    "\n",
    "def box_filter(img):\n",
    "    result = copy.copy(img)\n",
    "    cv2.blur(img, (2, 2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Filter\n",
    "\n",
    "def gaussian_filter(img, kernel_size):\n",
    "    result = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "    return result\n",
    "\n",
    "# Gaussian Filter Kernel Size 3\n",
    "\n",
    "def gaussian_filter_3(img):\n",
    "    result = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    return result\n",
    "\n",
    "# Gaussian Filter Kernel Size 5\n",
    "\n",
    "def gaussian_filter_5(img):\n",
    "    result = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lanczos Filter\n",
    "\n",
    "def lanczos_filter_single_channel(img):\n",
    "    lanczos_kernel = np.array([[0, -0.032, 0, 0.284, 0.496, 0.284, 0, -0.032, 0]])\n",
    "    return signal.convolve(signal.convolve(img, lanczos_kernel, mode='same'), lanczos_kernel.T, mode='same')\n",
    "\n",
    "def lanczos_filter(img):\n",
    "    # separate the channels\n",
    "    img_r = img[:,:,0]\n",
    "    img_g = img[:,:,1]\n",
    "    img_b = img[:,:,2]\n",
    "    \n",
    "    # apply lanczos filter to every channel individually\n",
    "    result_r = lanczos_filter_single_channel(img_r)\n",
    "    result_g = lanczos_filter_single_channel(img_g)\n",
    "    result_b = lanczos_filter_single_channel(img_b)\n",
    "    \n",
    "    # stack the channels back\n",
    "    result = np.dstack((result_r, result_g, result_b))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinc Filter\n",
    "\n",
    "def sinc_filter_single_channel(img):\n",
    "    rows, cols = img.shape\n",
    "    crow, ccol = int(rows/2), int(cols/2)\n",
    "    \n",
    "    # perform a discrete fourier transform\n",
    "    dft = cv2.dft(np.float32(img), flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "    \n",
    "    # cut off high frequencies\n",
    "    mask = np.zeros((rows,cols,2),np.uint8)\n",
    "    mask[crow-30:crow+30, ccol-30:ccol+30] = 1\n",
    "    fshift = dft_shift * mask\n",
    "    \n",
    "    # perform an inverse discrete fourier transform\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    img_res = cv2.idft(f_ishift, flags=cv2.DFT_SCALE | cv2.DFT_REAL_OUTPUT)\n",
    "    \n",
    "    return img_res\n",
    "\n",
    "def sinc_filter(img):\n",
    "    rows, cols, channels = img.shape\n",
    "    crow,ccol = int(rows/2), int(cols/2)\n",
    "    \n",
    "    # separate the channels\n",
    "    img_r = img[:,:,0]\n",
    "    img_g = img[:,:,1]\n",
    "    img_b = img[:,:,2]\n",
    "    \n",
    "    # apply sinc filter to every channel individually\n",
    "    img_res_r = sinc_filter_single_channel(img_r)\n",
    "    img_res_g = sinc_filter_single_channel(img_g)\n",
    "    img_res_b = sinc_filter_single_channel(img_b)\n",
    "    \n",
    "    # stack the channels back\n",
    "    result = np.dstack((img_res_r, img_res_g, img_res_b))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "########### Subsampling #################\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take every first pixel\n",
    "\n",
    "def sample_first(img):\n",
    "    result = img[::2, ::2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take every second pixel\n",
    "\n",
    "def sample_second(img):\n",
    "    result = img[::2, 1::2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take every third pixel\n",
    "\n",
    "def sample_third(img):\n",
    "    result = img[1::2, ::2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take every fourth pixel\n",
    "\n",
    "def sample_fourth(img):\n",
    "    result = img[1::2, 1::2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take average of four pixels\n",
    "\n",
    "def sample_average(img):\n",
    "#     result = (sample_first(img) + sample_second(img) + sample_third(img) + sample_fourth(img)) / 4;\n",
    "    result = skimage.measure.block_reduce(img, (2,2,1), np.mean)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take max of four pixels\n",
    "\n",
    "def sample_max(img):\n",
    "    result = skimage.measure.block_reduce(img, (2,2,1), np.max)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take min of four pixels\n",
    "\n",
    "def sample_min(img):\n",
    "    result = skimage.measure.block_reduce(img, (2,2,1), np.min)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take median of four pixels\n",
    "\n",
    "def sample_median(img):\n",
    "    result = skimage.measure.block_reduce(img, (2,2,1), np.median)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take random of four pixels\n",
    "\n",
    "def sample_random(img):\n",
    "    rows, cols, channels = img.shape\n",
    "    result = np.zeros((rows // 2, cols // 2, 3))\n",
    "    rx = 0\n",
    "    ry = 0\n",
    "    for i in range(0, rows - 1, 2):\n",
    "        ry = 0\n",
    "        for j in range(0, cols - 1, 2):\n",
    "            x = np.random.choice([i, i + 1])\n",
    "            y = np.random.choice([j, j + 1])\n",
    "            result[rx][ry] = img[x][y]\n",
    "            ry = ry + 1\n",
    "        rx = rx + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take most extreme of four pixels\n",
    "\n",
    "def get_abs(rgb):\n",
    "    r = rgb[0]\n",
    "    g = rgb[1]\n",
    "    b = rgb[2]\n",
    "    return r*r + g*g + b*b\n",
    "\n",
    "def sample_extreme(img):\n",
    "    rows, cols, channels = img.shape\n",
    "    result = np.zeros((rows // 2, cols // 2, 3))\n",
    "    rx = 0\n",
    "    ry = 0\n",
    "    for i in range(0, rows - 1, 2):\n",
    "        ry = 0\n",
    "        for j in range(0, cols - 1, 2):\n",
    "            mean = (img[i][j] + img[i][j+1] + img[i+1][j] + img[i+1][j+1]) / 4\n",
    "            mean_abs = get_abs(mean)\n",
    "            max_diff = 0\n",
    "            val = [0, 0, 0]\n",
    "            \n",
    "            for x in range(i, i + 2):\n",
    "                for y in range(j, j + 2):\n",
    "                    diff = abs(get_abs(img[x][y]) - mean_abs)\n",
    "                    if diff > max_diff:\n",
    "                        val = img[x][y]\n",
    "                        max_diff = diff\n",
    "            \n",
    "            result[rx][ry] = val\n",
    "            ry = ry + 1\n",
    "        rx = rx + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Comparison Functions #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get SSIM\n",
    "\n",
    "def get_ssim(original, downscaled):\n",
    "    scale = original.shape[0] / downscaled.shape[0]\n",
    "    img1 = torch.from_numpy(np.rollaxis(original, 2)).float().unsqueeze(0)/255.0\n",
    "    upscaled_from_downscaled = cv2.resize(downscaled, None, fx = scale, fy = scale, interpolation = cv2.INTER_LINEAR)\n",
    "    img2 = torch.from_numpy(np.rollaxis(upscaled_from_downscaled, 2)).float().unsqueeze(0)/255.0\n",
    "    return pytorch_msssim.msssim(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of low pass filters and subsampling methods\n",
    "\n",
    "low_pass_filters = {\n",
    "    \"box\": box_filter,\n",
    "    \"gaussian_3\": gaussian_filter_3,\n",
    "    \"gaussian_5\": gaussian_filter_5,\n",
    "    \"lanczos\": lanczos_filter,\n",
    "    \"sinc\": sinc_filter\n",
    "#     \"mlaagic\": magic_filter\n",
    "}\n",
    "\n",
    "subsampling_methods = {\n",
    "    \"first\": sample_first,\n",
    "    \"second\": sample_second,\n",
    "    \"third\": sample_third,\n",
    "    \"fourth\": sample_fourth,\n",
    "    \"average\": sample_average,\n",
    "    \"max\": sample_max,\n",
    "    \"min\": sample_min,\n",
    "    \"median\": sample_median,\n",
    "    \"random\": sample_random,\n",
    "    \"extreme\": sample_extreme\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "# folder containing 256x256 images\n",
    "IMAGE_DIR = 'C:/Users/sukan/Documents/TUM/Courses/Winter 2019/Thesis/Westermann - Texture Map/threejsrockstutorial/mipmap_LPF_SS'\n",
    "INPUT_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derived constants\n",
    "\n",
    "INPUT_DIR_NAME = str(INPUT_SIZE) + 'x' + str(INPUT_SIZE)\n",
    "IMAGE_INPUT_DIR = os.path.join(IMAGE_DIR, INPUT_DIR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process files\n",
    "\n",
    "file_names = os.listdir(IMAGE_INPUT_DIR)\n",
    "images = []\n",
    "cnt = 0\n",
    "print(str(len(file_names)) + \" files found.\")\n",
    "for file_name in file_names:\n",
    "    images.append({\n",
    "        \"name\": file_name,\n",
    "        \"image\": cv2.imread(os.path.join(IMAGE_INPUT_DIR, file_name))\n",
    "    })\n",
    "    cnt = cnt + 1\n",
    "    if (cnt % 100 == 0):\n",
    "        print('read ' + str(cnt) + ' images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downscale image files - generate mipmaps\n",
    "\n",
    "curr_size = INPUT_SIZE\n",
    "first_input_folder = True\n",
    "\n",
    "while (curr_size >= 2):\n",
    "    print (\"input size: \" + str(curr_size))\n",
    "    curr_output_size = int(curr_size / 2)\n",
    "    curr_input_folder_name = str(curr_size) + 'x' + str(curr_size)\n",
    "    curr_output_folder_name = str(curr_output_size) + 'x' + str(curr_output_size)\n",
    "    curr_input_folder = os.path.join(IMAGE_DIR, curr_input_folder_name)\n",
    "    curr_output_folder = os.path.join(IMAGE_DIR, curr_output_folder_name, 'lpf_ss')\n",
    "    \n",
    "    read all images in current input folder\n",
    "    file_names = os.listdir(curr_input_folder)\n",
    "    \n",
    "    # loop through all lpfs\n",
    "    for lpf in low_pass_filters:\n",
    "        print(\"lpf: \" + lpf)\n",
    "        # loop through all subsampling methods\n",
    "        for ss in subsampling_methods:\n",
    "            print(\"ss: \" + ss)\n",
    "            lpf_ss_folder = lpf + '_' + ss\n",
    "            \n",
    "            if (first_input_folder):\n",
    "                curr_lpf_ss_input_folder = curr_input_folder\n",
    "            else:\n",
    "                curr_lpf_ss_input_folder = os.path.join(curr_input_folder, 'lpf_ss', lpf_ss_folder)\n",
    "                file_names = os.listdir(curr_lpf_ss_input_folder)\n",
    "            \n",
    "            curr_lpf_ss_output_folder = os.path.join(curr_output_folder, lpf_ss_folder)\n",
    "            \n",
    "            # if images for this lpf and ss and size have been generated move on to next ss\n",
    "            if not (os.path.exists(curr_lpf_ss_output_folder)):\n",
    "                os.mkdir(curr_lpf_ss_output_folder)\n",
    "            \n",
    "            c = 0\n",
    "            for file_name in file_names:\n",
    "                image = cv2.imread(os.path.join(curr_lpf_ss_input_folder, file_name))\n",
    "                output_image_path = os.path.join(curr_lpf_ss_output_folder, file_name)\n",
    "                \n",
    "                if (os.path.exists(output_image_path)):\n",
    "                    continue\n",
    "                \n",
    "                c = c + 1\n",
    "                lpf_image = low_pass_filters[lpf](image)\n",
    "                downscaled = subsampling_methods[ss](lpf_image).astype(np.uint8)\n",
    "                cv2.imwrite(output_image_path, downscaled)\n",
    "#             print (str(c) + \" images downscaled now.\")\n",
    "    \n",
    "    curr_size = int(curr_size / 2)\n",
    "    first_input_folder = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
